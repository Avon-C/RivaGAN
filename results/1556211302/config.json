{
  "lr": 0.0001,
  "epochs": 200,
  "dataset": "hollywood2",
  "seq_len": 1,
  "data_dim": 32,
  "batch_size": 12,
  "multiplicity": 1,
  "experiment": "attention",
  "combiner": "spatial_repeat",
  "note": "this is attention with batch norm"
}